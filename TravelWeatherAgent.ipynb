{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-google-genai langchain-core langchain-community requests \\\n",
        "    google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrDDFIfedkLp",
        "outputId": "13a4fcf7-4bb0-48ac-a643-0a2c2fe9e561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GEMINI KEY"
      ],
      "metadata": {
        "id": "s6G9MVhghCJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, getpass\n",
        "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\") or getpass.getpass(\"Paste your Gemini API key: \")\n",
        "assert os.environ[\"GOOGLE_API_KEY\"], \"No Gemini API key set.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZd4vkdGdkmp",
        "outputId": "f9bcb996-a739-466d-ff5e-ec92e7c3b86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your Gemini API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INIT GEMI"
      ],
      "metadata": {
        "id": "OvD8ypl7hGye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Use a cheap, fast model; switch to \"gemini-1.5-pro\" if you want stronger reasoning.\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.3)\n"
      ],
      "metadata": {
        "id": "DrIFT3fieIgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WEATHER"
      ],
      "metadata": {
        "id": "UfbmNm8FhOtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_core.tools import tool\n",
        "import requests, json\n",
        "\n",
        "                          ######################### Weather code mapping from Open-Meteo docs (condensed)####################################\n",
        "WEATHER_CODES = {\n",
        "    0:\"Clear\", 1:\"Mainly clear\", 2:\"Partly cloudy\", 3:\"Overcast\",\n",
        "    45:\"Fog\", 48:\"Depositing rime fog\",\n",
        "    51:\"Light drizzle\", 53:\"Moderate drizzle\", 55:\"Dense drizzle\",\n",
        "    56:\"Freezing drizzle (light)\", 57:\"Freezing drizzle (dense)\",\n",
        "    61:\"Slight rain\", 63:\"Moderate rain\", 65:\"Heavy rain\",\n",
        "    66:\"Freezing rain (light)\", 67:\"Freezing rain (heavy)\",\n",
        "    71:\"Slight snow\", 73:\"Moderate snow\", 75:\"Heavy snow\",\n",
        "    77:\"Snow grains\",\n",
        "    80:\"Rain showers (slight)\", 81:\"Rain showers (moderate)\", 82:\"Rain showers (violent)\",\n",
        "    85:\"Snow showers (slight)\", 86:\"Snow showers (heavy)\",\n",
        "    95:\"Thunderstorm (slight/moderate)\", 96:\"Thunderstorm w/ slight hail\", 99:\"Thunderstorm w/ heavy hail\"\n",
        "}\n",
        "\n",
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"\n",
        "    Return current weather for a city using the free Open-Meteo API.\n",
        "    Input: plain city name (e.g., \"Hyderabad\").\n",
        "    Output: JSON string with city, country, temp (°C), humidity (%), wind (m/s), condition.\n",
        "    \"\"\"\n",
        "    if not city or not city.strip():\n",
        "        return \"City name is empty.\"\n",
        "\n",
        "    # 1) Geocode city -> lat/lon\n",
        "    g = requests.get(\n",
        "        \"https://geocoding-api.open-meteo.com/v1/search\",\n",
        "        params={\"name\": city, \"count\": 1, \"language\": \"en\"}\n",
        "    )\n",
        "    g.raise_for_status()\n",
        "    gjs = g.json()\n",
        "    if not gjs.get(\"results\"):\n",
        "        return f\"City '{city}' not found.\"\n",
        "\n",
        "    r0 = gjs[\"results\"][0]\n",
        "    lat, lon = r0[\"latitude\"], r0[\"longitude\"]\n",
        "    name, country, tz = r0.get(\"name\"), r0.get(\"country\"), r0.get(\"timezone\", \"auto\")\n",
        "\n",
        "    # 2) Current weather\n",
        "    w = requests.get(\n",
        "        \"https://api.open-meteo.com/v1/forecast\",\n",
        "        params={\n",
        "            \"latitude\": lat, \"longitude\": lon, \"timezone\": tz,\n",
        "            \"current\": \"temperature_2m,relative_humidity_2m,wind_speed_10m,weather_code\"\n",
        "        }\n",
        "    )\n",
        "    w.raise_for_status()\n",
        "    wj = w.json()\n",
        "    cur = wj.get(\"current\", {})\n",
        "\n",
        "    code = int(cur.get(\"weather_code\", -1)) if cur.get(\"weather_code\") is not None else -1\n",
        "    desc = WEATHER_CODES.get(code, \"Unknown\")\n",
        "\n",
        "    payload = {\n",
        "        \"city\": name, \"country\": country, \"timezone\": tz,\n",
        "        \"latitude\": lat, \"longitude\": lon,\n",
        "        \"temperature_c\": cur.get(\"temperature_2m\"),\n",
        "        \"humidity_percent\": cur.get(\"relative_humidity_2m\"),\n",
        "        \"wind_speed_mps\": cur.get(\"wind_speed_10m\"),\n",
        "        \"condition\": desc,\n",
        "    }\n",
        "    return json.dumps(payload)\n"
      ],
      "metadata": {
        "id": "3H3mROZDeThM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PACKING ITEMS"
      ],
      "metadata": {
        "id": "IVJmOeSihTvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.schema import Document\n",
        "!pip install -q langchain-google-genai langchain-core langchain-community requests \\\n",
        "    google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 faiss-cpu\n",
        "\n",
        "\n",
        "# Example FAQ data\n",
        "faq_text = \"\"\"\n",
        "Packing Tips:\n",
        "- Always carry a light jacket, even in warm cities.\n",
        "- For rainy places, carry an umbrella or raincoat.\n",
        "- Wear comfortable shoes for walking.\n",
        "\n",
        "Travel Safety:\n",
        "- Keep copies of your documents in case of loss.\n",
        "- Avoid isolated areas at night.\n",
        "- Stay hydrated in hot weather.\n",
        "\n",
        "Seasonal Advice:\n",
        "- Summer: Light clothes, sunscreen, hat.\n",
        "- Winter: Layered clothing, gloves, thermal wear.\n",
        "- Monsoon: Waterproof shoes, quick-dry clothes.\n",
        "\"\"\"\n",
        "\n",
        "# Create chunks for embedding\n",
        "docs = [Document(page_content=faq_text)]\n",
        "splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "retriever = vectorstore.as_retriever()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouZvVvgPgGsG",
        "outputId": "567b66a6-89bc-46d2-a25e-d70a6e0d52a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI AGENT + RAG"
      ],
      "metadata": {
        "id": "_fIt5O_7hay4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "@tool\n",
        "def travel_faq(query: str) -> str:\n",
        "    \"\"\"Search travel FAQ for advice.\"\"\"\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    if not results:\n",
        "        return \"No advice found.\"\n",
        "    return \"\\n\".join([r.page_content for r in results])\n",
        "\n",
        "tools = [get_weather, travel_faq]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are TravelMate, an AI agent that answers travel questions and fetches real-time weather. \"\n",
        "     \"If user asks about weather, call 'get_weather'. \"\n",
        "     \"If user asks for packing tips or travel safety, call 'travel_faq'. \"\n",
        "     \"Always give short, practical answers.\"),\n",
        "    # Few-shot example\n",
        "    (\"human\", \"I'm going to Mumbai in July, what should I pack?\"),\n",
        "    (\"ai\", \"July in Mumbai is monsoon season. Carry a raincoat, umbrella, waterproof shoes, and light clothes.\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
      ],
      "metadata": {
        "id": "zKBTkvLQeane"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ask about weather or travel advice (type 'exit' to quit).\")\n",
        "while True:\n",
        "    q = input(\"\\nYou: \").strip()\n",
        "    if q.lower() in (\"exit\", \"quit\"):\n",
        "        break\n",
        "    out = agent_executor.invoke({\"input\": q})\n",
        "    print(\"\\nBot:\", out[\"output\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "h6cPbvMsefIf",
        "outputId": "b058879e-c911-48df-9bd9-e766ba8d089f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask about weather or travel advice (type 'exit' to quit).\n",
            "\n",
            "You: hey tomm going to madurai can  tell wheter\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `get_weather` with `{'city': 'Madurai'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{\"city\": \"Madurai\", \"country\": \"India\", \"timezone\": \"Asia/Kolkata\", \"latitude\": 9.919, \"longitude\": 78.11953, \"temperature_c\": 31.6, \"humidity_percent\": 55, \"wind_speed_mps\": 11.6, \"condition\": \"Overcast\"}\u001b[0m\u001b[32;1m\u001b[1;3mMadurai weather: 31.6°C, overcast, 55% humidity, 11.6 m/s wind.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Bot: Madurai weather: 31.6°C, overcast, 55% humidity, 11.6 m/s wind.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-84701562.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ask about weather or travel advice (type 'exit' to quit).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nYou: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}
